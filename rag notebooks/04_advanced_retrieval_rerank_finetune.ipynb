{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 ‚Äì Advanced Retrieval: Hybrid Search & Reranking\n",
        "\n",
        "**Learning Goals:**\n",
        "- Understand dense vs sparse retrieval trade-offs\n",
        "- Implement BM25 keyword-based search\n",
        "- Combine retrieval methods using Reciprocal Rank Fusion (RRF)\n",
        "- Apply cross-encoder reranking for improved precision\n",
        "\n",
        "**What we'll cover:**\n",
        "1. **Step 1: Data Loading** - Load dermatology corpus from text files\n",
        "2. **Step 2: Dense Retrieval** - Vector similarity search with ChromaDB\n",
        "3. **Step 3: Sparse Retrieval** - BM25 keyword matching\n",
        "4. **Step 4: Hybrid Fusion** - Combine dense + sparse with RRF\n",
        "5. **Step 5: Reranking** - Cross-encoder for refined relevance\n",
        "\n",
        "**Prerequisites:** Notebooks 01, 02, 03 completed\n",
        "\n",
        "**Key Insight:** No single retrieval method is best for all queries. Hybrid approaches combine the semantic understanding of dense retrieval with the keyword precision of sparse retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Working directory: /Users/machinelearningzuu/Dropbox/Zuu Crew/Courses/üöß AI Engineer Essentials/Live Classes/Week 03\n",
            "‚úÖ Config loaded:\n",
            "  LLM: openrouter (openai/gpt-4o-mini)\n",
            "  Embeddings: sbert / sentence-transformers/all-MiniLM-L6-v2\n",
            "  Temperature: 0.2\n",
            "  Artifacts: ./artifacts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/machinelearningzuu/Dropbox/Zuu Crew/Courses/üöß AI Engineer Essentials/Live Classes/Week 03/src/services/llm_services.py:375: UserWarning: ‚ö†Ô∏è  GROQ_API_KEY not found in environment\n",
            "  warnings.warn(f\"‚ö†Ô∏è  {key} not found in environment\")\n",
            "/Users/machinelearningzuu/Dropbox/Zuu Crew/Courses/üöß AI Engineer Essentials/Live Classes/Week 03/src/services/llm_services.py:375: UserWarning: ‚ö†Ô∏è  GOOGLE_API_KEY not found in environment\n",
            "  warnings.warn(f\"‚ö†Ô∏è  {key} not found in environment\")\n",
            "/Users/machinelearningzuu/Dropbox/Zuu Crew/Courses/üöß AI Engineer Essentials/Live Classes/Week 03/src/services/llm_services.py:375: UserWarning: ‚ö†Ô∏è  COHERE_API_KEY not found in environment\n",
            "  warnings.warn(f\"‚ö†Ô∏è  {key} not found in environment\")\n"
          ]
        }
      ],
      "source": [
        "# ‚öôÔ∏è Global Config & Services (using centralized modules)\n",
        "\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Add parent directory to path and change to project root\n",
        "import os\n",
        "\n",
        "# Get the notebook's current directory and find project root\n",
        "notebook_dir = Path.cwd()\n",
        "if notebook_dir.name == \"notebooks\":\n",
        "    project_root = notebook_dir.parent\n",
        "else:\n",
        "    project_root = notebook_dir\n",
        "\n",
        "# Change to project root and add to path\n",
        "os.chdir(project_root)\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
        "\n",
        "from src.services.llm_services import (\n",
        "    load_config,\n",
        "    get_llm,\n",
        "    get_text_embeddings,\n",
        "    validate_api_keys,\n",
        "    print_config_summary\n",
        ")\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Load configuration from config.yaml (now we're in project root)\n",
        "config = load_config(\"src/config/config.yaml\")\n",
        "\n",
        "# Validate API keys\n",
        "validate_api_keys(config, verbose=True)\n",
        "\n",
        "# Print summary\n",
        "print_config_summary(config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/machinelearningzuu/Dropbox/Zuu Crew/Courses/üöß AI Engineer Essentials/Live Classes/Week 03/src/services/llm_services.py:129: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  return HuggingFaceEmbeddings(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ LLM: openrouter / gpt-4o-mini\n",
            "‚úÖ Embeddings: sentence-transformers/all-MiniLM-L6-v2\n",
            "‚úÖ Reranker: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "\n",
            "üîç Testing LLM API connection...\n",
            "‚úÖ LLM API verified: API working!\n"
          ]
        }
      ],
      "source": [
        "# Initialize LLM, Embeddings, and Reranker\n",
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "llm = get_llm(config)\n",
        "embeddings = get_text_embeddings(config)\n",
        "\n",
        "# CrossEncoder: A reranker model that scores query-document pairs\n",
        "# Unlike bi-encoders (embeddings), cross-encoders see query AND document together\n",
        "# This gives higher accuracy but is slower (can't pre-compute embeddings)\n",
        "reranker = CrossEncoder(\n",
        "    \"cross-encoder/ms-marco-MiniLM-L-6-v2\"  # Model trained on MS MARCO dataset\n",
        "                                             # Other options: \"cross-encoder/ms-marco-TinyBERT-L-2-v2\" (faster)\n",
        "                                             #                \"cross-encoder/ms-marco-MiniLM-L-12-v2\" (more accurate)\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ LLM: {config['llm_provider']} / {config.get('openrouter_model', config.get('llm_model'))}\")\n",
        "print(f\"‚úÖ Embeddings: {config['text_emb_model']}\")\n",
        "print(f\"‚úÖ Reranker: cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "\n",
        "# Verify API key with test completion\n",
        "print(\"\\nüîç Testing LLM API connection...\")\n",
        "try:\n",
        "    test_response = llm.invoke(\"Say 'API working!' if you can read this.\")\n",
        "    test_msg = test_response.content if hasattr(test_response, 'content') else str(test_response)\n",
        "    print(f\"‚úÖ LLM API verified: {test_msg[:50]}\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå LLM API test failed: {e}\")\n",
        "    print(\"‚ö†Ô∏è  Please check your .env file and API key configuration.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 1: Load or Create Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìö Loading dermatology corpus from raw_text files...\n",
            "  Loading: Understanding Skin Diseases.txt\n",
            "  Loading: skin-care habits.txt\n",
            "‚úÖ Loaded 34 dermatology documents from text files\n",
            "  Average length: 348 chars\n",
            "  Topics: eczema, psoriasis, fungal infections, treatments\n",
            "\n",
            "Sample: Sure ‚Äî here‚Äôs a detailed and comprehensive overview of skin diseases, written in an informative, medically accurate styl...\n"
          ]
        }
      ],
      "source": [
        "from langchain.schema import Document\n",
        "import re\n",
        "\n",
        "# Load corpus dynamically from raw_text files\n",
        "text_dir = Path(config[\"data_root\"]) / \"raw_text\"\n",
        "\n",
        "def load_and_chunk_text_files(directory: Path, chunk_size: int = 500):\n",
        "    \"\"\"Load text files and chunk them into manageable paragraphs.\"\"\"\n",
        "    corpus = []\n",
        "    \n",
        "    for txt_file in directory.glob(\"*.txt\"):\n",
        "        print(f\"  Loading: {txt_file.name}\")\n",
        "        content = txt_file.read_text(encoding='utf-8')\n",
        "        \n",
        "        # Split by double newlines (paragraphs) or section markers\n",
        "        paragraphs = re.split(r'\\n\\n+|‚∏ª', content)\n",
        "        \n",
        "        for para in paragraphs:\n",
        "            # Clean and normalize\n",
        "            para = para.strip()\n",
        "            \n",
        "            # Skip very short paragraphs, headers, or empty lines\n",
        "            if len(para) < 50 or para.startswith('‚Ä¢') or para.startswith('#'):\n",
        "                continue\n",
        "            \n",
        "            # Remove excessive whitespace and bullet points\n",
        "            para = re.sub(r'\\s+', ' ', para)\n",
        "            para = re.sub(r'^\\s*[‚Ä¢\\-]\\s*', '', para)\n",
        "            \n",
        "            # Skip if still too short after cleaning\n",
        "            if len(para) < 100:\n",
        "                continue\n",
        "                \n",
        "            corpus.append(para)\n",
        "    \n",
        "    return corpus\n",
        "\n",
        "print(\"üìö Loading dermatology corpus from raw_text files...\")\n",
        "corpus = load_and_chunk_text_files(text_dir)\n",
        "\n",
        "# Create documents with metadata\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=text, \n",
        "        metadata={\n",
        "            'doc_id': i, \n",
        "            'source': 'dermatology_corpus',\n",
        "            'length': len(text)\n",
        "        }\n",
        "    ) \n",
        "    for i, text in enumerate(corpus)\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(documents)} dermatology documents from text files\")\n",
        "\n",
        "# Check if loaded successfully - add fallback if empty\n",
        "if len(documents) == 0:\n",
        "    print(\"‚ö†Ô∏è  No documents from raw_text. Creating sample corpus...\")\n",
        "    sample_texts = [\n",
        "        \"Eczema (atopic dermatitis) is a chronic inflammatory skin condition. Treatment includes daily moisturizing, topical corticosteroids during flare-ups, and avoiding triggers.\",\n",
        "        \"Psoriasis is an autoimmune condition causing rapid skin cell turnover, resulting in thick, silvery scales. Common treatments include topical corticosteroids, phototherapy, and systemic medications.\",\n",
        "        \"Fungal infections (tinea) such as ringworm are caused by dermatophytes. Treatment involves topical antifungal creams like terbinafine applied for 2-4 weeks.\",\n",
        "        \"Acne vulgaris occurs when hair follicles become clogged. Treatment options include topical retinoids, benzoyl peroxide, and oral antibiotics for severe cases.\",\n",
        "        \"Contact dermatitis results from skin exposure to irritants or allergens. Management involves identifying and avoiding triggers.\",\n",
        "        \"Rosacea causes facial redness and visible blood vessels. Treatment includes avoiding triggers and topical medications like metronidazole.\",\n",
        "        \"Seborrheic dermatitis causes scaly patches on the scalp. Treatment includes medicated shampoos containing ketoconazole.\",\n",
        "        \"Vitiligo causes loss of skin pigmentation. Management includes sun protection, topical corticosteroids, and phototherapy.\",\n",
        "    ]\n",
        "    documents = [\n",
        "        Document(page_content=text, metadata={\"doc_id\": i, \"source\": \"sample_corpus\", \"length\": len(text)})\n",
        "        for i, text in enumerate(sample_texts)\n",
        "    ]\n",
        "    print(f\"‚úÖ Created {len(documents)} sample documents\")\n",
        "\n",
        "if len(documents) > 0:\n",
        "    avg_len = sum(len(d.page_content) for d in documents) // len(documents)\n",
        "    print(f\"  Average length: {avg_len} chars\")\n",
        "    print(f\"  Topics: eczema, psoriasis, fungal infections, treatments\")\n",
        "    print(f\"\\nSample: {documents[0].page_content[:120]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 2: Dense Retrieval (ChromaDB)\n",
        "\n",
        "Build a vector store using dense embeddings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîµ Building dense vector store...\n",
            "‚úÖ Dense index built: 34 docs\n",
            "\n",
            "üîç Dense search: 'What are treatments for eczema?'\n",
            "  [1] Eczema (atopic dermatitis) ‚Ä¢ Core remedies: daily emollients, short lukewarm baths/showers, fragranc...\n",
            "  [2] Eczema (atopic dermatitis) ‚Ä¢ Core remedies: daily emollients, short lukewarm baths/showers, fragranc...\n",
            "  [3] Eczema (atopic dermatitis) ‚Ä¢ Core remedies: daily emollients, short lukewarm baths/showers, fragranc...\n",
            "  [4] Eczema (atopic dermatitis) ‚Ä¢ Core remedies: daily emollients, short lukewarm baths/showers, fragranc...\n",
            "  [5] Treatment depends on the underlying cause and may include: ‚Ä¢ Topical medications: Corticosteroids, a...\n",
            "  [6] Treatment depends on the underlying cause and may include: ‚Ä¢ Topical medications: Corticosteroids, a...\n",
            "  [7] Treatment depends on the underlying cause and may include: ‚Ä¢ Topical medications: Corticosteroids, a...\n",
            "  [8] Treatment depends on the underlying cause and may include: ‚Ä¢ Topical medications: Corticosteroids, a...\n"
          ]
        }
      ],
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "# Setup persistence directory for ChromaDB\n",
        "chroma_root = Path(config[\"artifacts_root\"]) / \"chroma\"\n",
        "chroma_root.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"üîµ Building dense vector store...\")\n",
        "\n",
        "# Chroma.from_documents: Creates a vector store from LangChain Documents\n",
        "dense_vectorstore = Chroma.from_documents(\n",
        "    documents=documents,        # documents: List of Document objects to index\n",
        "    embedding=embeddings,       # embedding: Embedding model to convert text ‚Üí vectors\n",
        "    collection_name=\"advanced_dense\",  # collection_name: Name of the collection in ChromaDB\n",
        "    persist_directory=str(chroma_root / \"advanced_dense\"),  # persist_directory: Where to save the index\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Dense index built: {len(documents)} docs\")\n",
        "\n",
        "# Test dense retrieval\n",
        "query = \"What are treatments for eczema?\"\n",
        "\n",
        "# similarity_search: Find documents with vectors closest to query vector\n",
        "dense_results = dense_vectorstore.similarity_search(\n",
        "    query,  # query: Search query (will be embedded automatically)\n",
        "    k=8     # k: Number of top results to return\n",
        ")\n",
        "\n",
        "print(f\"\\nüîç Dense search: '{query}'\")\n",
        "for i, doc in enumerate(dense_results, 1):\n",
        "    print(f\"  [{i}] {doc.page_content[:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 3: Sparse Retrieval (BM25)\n",
        "\n",
        "Use BM25 for keyword-based retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üü† Building BM25 index...\n",
            "‚úÖ BM25 index built\n",
            "\n",
            "üîç BM25 search: 'What are treatments for eczema?'\n",
            "  [1] (score: 3.76) Actinic keratoses, BCC, SCC, melanoma ‚Ä¢ What helps: prevention & early detection. Follow the ABCDE s...\n",
            "  [2] (score: 2.61) Urticaria (hives) ‚Ä¢ What helps: for most, second-generation oral antihistamines (non-sedating) are f...\n",
            "  [3] (score: 2.21) 2) Fungal (tinea/ringworm, athlete‚Äôs foot, jock itch) ‚Ä¢ What helps at home: OTC antifungals (creams,...\n",
            "  [4] (score: 2.20) Skin diseases are among the most prevalent health problems worldwide. According to WHO and the Globa...\n",
            "  [5] (score: 1.60) These are caused by microorganisms such as bacteria, viruses, fungi, or parasites. ‚Ä¢ Bacterial infec...\n",
            "  [6] (score: 1.33) Acne (common, though not in your earlier list) ‚Ä¢ At home: gentle cleanse; benzoyl peroxide, adapalen...\n",
            "  [7] (score: 0.91) Vitiligo ‚Ä¢ What helps: strict sun protection to minimize contrast; dermatologist-directed topical co...\n",
            "  [8] (score: 0.89) 4) Viral (herpes simplex, shingles, warts) ‚Ä¢ What helps: clinician-guided antivirals for herpes/shin...\n"
          ]
        }
      ],
      "source": [
        "from rank_bm25 import BM25Okapi\n",
        "import numpy as np\n",
        "\n",
        "print(\"üü† Building BM25 index...\")\n",
        "\n",
        "# BM25 (Best Match 25): Classic sparse retrieval algorithm\n",
        "# Unlike dense retrieval, BM25 uses exact keyword matching with TF-IDF-like scoring\n",
        "\n",
        "# Step 1: Tokenize corpus (lowercase + split by whitespace)\n",
        "tokenized_corpus = [doc.page_content.lower().split() for doc in documents]\n",
        "\n",
        "# BM25Okapi: BM25 variant with Okapi weighting\n",
        "# Other variants: BM25L, BM25Plus (handle long documents better)\n",
        "bm25 = BM25Okapi(tokenized_corpus)\n",
        "\n",
        "print(f\"‚úÖ BM25 index built\")\n",
        "\n",
        "\n",
        "def bm25_search(query: str, top_k: int = 3):\n",
        "    \"\"\"\n",
        "    Search using BM25 (sparse retrieval algorithm).\n",
        "    \n",
        "    Args:\n",
        "        query: Search query string\n",
        "        top_k: Number of top results to return\n",
        "        \n",
        "    Returns:\n",
        "        List of dictionaries with doc, score, and doc_id\n",
        "    \"\"\"\n",
        "    # Tokenize query the same way as corpus\n",
        "    tokenized_query = query.lower().split()\n",
        "    \n",
        "    # Get BM25 scores for all documents\n",
        "    scores = bm25.get_scores(tokenized_query)\n",
        "    \n",
        "    # Find top-k indices (argsort ascending, then reverse for descending)\n",
        "    top_indices = np.argsort(scores)[::-1][:top_k]\n",
        "    \n",
        "    # Build results list\n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            \"doc\": documents[idx],\n",
        "            \"score\": float(scores[idx]),\n",
        "            \"doc_id\": idx\n",
        "        })\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Test BM25\n",
        "bm25_results = bm25_search(query, top_k=8)\n",
        "\n",
        "print(f\"\\nüîç BM25 search: '{query}'\")\n",
        "for i, res in enumerate(bm25_results, 1):\n",
        "    print(f\"  [{i}] (score: {res['score']:.2f}) {res['doc'].page_content[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 4: Hybrid Fusion (Dense + BM25)\n",
        "\n",
        "Combine dense and sparse retrieval using Reciprocal Rank Fusion (RRF).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîÄ Hybrid (RRF) search: 'What are treatments for eczema?'\n",
            "  [1] (RRF: 0.064) Eczema (atopic dermatitis) ‚Ä¢ Core remedies: daily emollients, short lukewarm baths/showers, fragranc...\n",
            "  [2] (RRF: 0.060) Treatment depends on the underlying cause and may include: ‚Ä¢ Topical medications: Corticosteroids, a...\n",
            "  [3] (RRF: 0.016) Actinic keratoses, BCC, SCC, melanoma ‚Ä¢ What helps: prevention & early detection. Follow the ABCDE s...\n",
            "  [4] (RRF: 0.016) Urticaria (hives) ‚Ä¢ What helps: for most, second-generation oral antihistamines (non-sedating) are f...\n",
            "  [5] (RRF: 0.016) 2) Fungal (tinea/ringworm, athlete‚Äôs foot, jock itch) ‚Ä¢ What helps at home: OTC antifungals (creams,...\n",
            "  [6] (RRF: 0.016) Skin diseases are among the most prevalent health problems worldwide. According to WHO and the Globa...\n",
            "  [7] (RRF: 0.015) These are caused by microorganisms such as bacteria, viruses, fungi, or parasites. ‚Ä¢ Bacterial infec...\n",
            "  [8] (RRF: 0.015) Acne (common, though not in your earlier list) ‚Ä¢ At home: gentle cleanse; benzoyl peroxide, adapalen...\n",
            "  [9] (RRF: 0.015) Vitiligo ‚Ä¢ What helps: strict sun protection to minimize contrast; dermatologist-directed topical co...\n",
            "  [10] (RRF: 0.015) 4) Viral (herpes simplex, shingles, warts) ‚Ä¢ What helps: clinician-guided antivirals for herpes/shin...\n"
          ]
        }
      ],
      "source": [
        "from typing import List\n",
        "\n",
        "def rrf_fusion(dense_docs: List, bm25_results: List, k: int = 60) -> List:\n",
        "    \"\"\"\n",
        "    Reciprocal Rank Fusion (RRF) - combines dense and sparse retrieval.\n",
        "    \n",
        "    RRF Formula: score(d) = Œ£ 1/(k + rank(d)) for each ranking\n",
        "    \n",
        "    - k=60 is the default constant (from original paper)\n",
        "    - Higher k ‚Üí more weight to lower-ranked documents\n",
        "    - Lower k ‚Üí more weight to top-ranked documents\n",
        "    \n",
        "    Args:\n",
        "        dense_docs: Results from dense (vector) retrieval\n",
        "        bm25_results: Results from BM25 (sparse) retrieval\n",
        "        k: RRF constant (default 60, typical range 1-100)\n",
        "        \n",
        "    Returns:\n",
        "        Fused results sorted by RRF score (higher = more relevant)\n",
        "    \"\"\"\n",
        "    rrf_scores = {}\n",
        "    \n",
        "    # Add scores from dense retrieval\n",
        "    for rank, doc in enumerate(dense_docs, 1):  # rank starts at 1\n",
        "        doc_id = doc.metadata[\"doc_id\"]\n",
        "        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0.0) + 1.0 / (k + rank)\n",
        "    \n",
        "    # Add scores from BM25 retrieval\n",
        "    for rank, doc in enumerate(bm25_results, 1):\n",
        "        doc_id = doc[\"doc_id\"]\n",
        "        rrf_scores[doc_id] = rrf_scores.get(doc_id, 0.0) + 1.0 / (k + rank)\n",
        "    \n",
        "    # Sort by combined RRF score (descending)\n",
        "    sorted_ids = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    # Build final results list\n",
        "    fused_docs = []\n",
        "    for doc_id, score in sorted_ids:\n",
        "        fused_docs.append({\n",
        "            \"doc\": documents[doc_id],\n",
        "            \"score\": score,\n",
        "            \"doc_id\": doc_id\n",
        "        })\n",
        "    \n",
        "    return fused_docs\n",
        "# Test hybrid fusion\n",
        "fused_results = rrf_fusion(dense_results, bm25_results)\n",
        "\n",
        "print(f\"üîÄ Hybrid (RRF) search: '{query}'\")\n",
        "for i, res in enumerate(fused_results, 1):\n",
        "    print(f\"  [{i}] (RRF: {res['score']:.3f}) {res['doc'].page_content[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Step 5: Reranking with Cross-Encoder\n",
        "\n",
        "Refine results using a cross-encoder for more accurate relevance scoring.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why Rerank?\n",
        "\n",
        "**The Problem:**\n",
        "- Dense retrieval is fast but approximate\n",
        "- Getting top-10 from 10,000 chunks may miss relevant docs\n",
        "\n",
        "**The Solution: Two-Stage Retrieval**\n",
        "```\n",
        "Stage 1: Fast retrieval (dense + BM25) ‚Üí 100 candidates\n",
        "Stage 2: Rerank with cross-encoder ‚Üí 10 final results\n",
        "```\n",
        "\n",
        "**Cross-encoders vs Bi-encoders:**\n",
        "- **Bi-encoder** (embeddings): Encodes query and doc separately ‚Üí fast but less accurate\n",
        "- **Cross-encoder**: Encodes query+doc together ‚Üí slow but more accurate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÜ Reranked results: 'What are treatments for eczema?'\n",
            "  [1] (rerank: 4.700) Eczema (atopic dermatitis) ‚Ä¢ Core remedies: daily emollients, short lukewarm baths/showers, fragranc...\n",
            "  [2] (rerank: -1.330) Treatment depends on the underlying cause and may include: ‚Ä¢ Topical medications: Corticosteroids, a...\n",
            "  [3] (rerank: -1.724) Actinic keratoses, BCC, SCC, melanoma ‚Ä¢ What helps: prevention & early detection. Follow the ABCDE s...\n"
          ]
        }
      ],
      "source": [
        "def rerank(query: str, results: List, top_k: int = 3):\n",
        "    \"\"\"\n",
        "    Rerank results using a cross-encoder for more accurate relevance scoring.\n",
        "    \n",
        "    Cross-encoder sees [query, document] together, enabling deeper understanding\n",
        "    of relevance than separate embeddings.\n",
        "    \n",
        "    Args:\n",
        "        query: Search query string\n",
        "        results: List of initial results to rerank (from fusion)\n",
        "        top_k: Number of top results to return after reranking\n",
        "        \n",
        "    Returns:\n",
        "        Reranked results with rerank_score added (higher = more relevant)\n",
        "    \"\"\"\n",
        "    # Create query-document pairs for cross-encoder\n",
        "    # Format: [[query, doc1], [query, doc2], ...]\n",
        "    pairs = [[query, res['doc'].page_content] for res in results]\n",
        "    \n",
        "    # Cross-encoder predicts relevance score for each pair\n",
        "    # Returns array of scores (can be negative, higher = more relevant)\n",
        "    scores = reranker.predict(pairs)\n",
        "    \n",
        "    # Add rerank scores to results\n",
        "    for i, res in enumerate(results):\n",
        "        res['rerank_score'] = float(scores[i])\n",
        "    \n",
        "    # Sort by rerank score (descending) and take top-k\n",
        "    reranked = sorted(results, key=lambda x: x['rerank_score'], reverse=True)[:top_k]\n",
        "    return reranked\n",
        "\n",
        "# Test reranking\n",
        "reranked_results = rerank(query, fused_results[:6], top_k=3)\n",
        "\n",
        "print(f\"üèÜ Reranked results: '{query}'\")\n",
        "for i, res in enumerate(reranked_results, 1):\n",
        "    print(f\"  [{i}] (rerank: {res['rerank_score']:.3f}) {res['doc'].page_content[:100]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Bonus Exercise: Complete Hybrid RAG Pipeline\n",
        "\n",
        "**Challenge:** Combine all techniques into a single end-to-end pipeline!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Testing Complete Hybrid RAG Pipeline\n",
            "\n",
            "Query: What are treatments for eczema?\n",
            "\n",
            "Pipeline stats:\n",
            "  Dense retrieval: 10 docs\n",
            "  BM25 retrieval: 10 docs\n",
            "  After fusion: 6 docs\n",
            "  After reranking: 3 docs\n",
            "\n",
            "Final Answer:\n",
            "Treatments for eczema include daily emollients, short lukewarm baths/showers, fragrance-free products, and trigger avoidance. For flares, clinicians may prescribe topical anti-inflammatories (steroids or non-steroids), wet-wraps, and selected phototherapy for moderate to severe cases. Additionally, dilute bleach baths may be recommended by a dermatologist to reduce Staph burden and itch.\n"
          ]
        }
      ],
      "source": [
        "def hybrid_rag_pipeline(\n",
        "    query: str, \n",
        "    dense_top_n: int = 10,   # dense_top_n: How many docs to retrieve with dense search\n",
        "    bm25_top_n: int = 10,    # bm25_top_n: How many docs to retrieve with BM25\n",
        "    rerank_top_n: int = 6,   # rerank_top_n: How many fused results to rerank\n",
        "    final_top_k: int = 3     # final_top_k: Final number of docs for LLM context\n",
        "):\n",
        "    \"\"\"\n",
        "    Complete hybrid RAG pipeline combining all advanced techniques.\n",
        "    \n",
        "    Pipeline: Dense ‚Üí BM25 ‚Üí Fusion (RRF) ‚Üí Rerank ‚Üí LLM Generation\n",
        "    \n",
        "    Args:\n",
        "        query: User question\n",
        "        dense_top_n: Number of results from dense retrieval\n",
        "        bm25_top_n: Number of results from BM25\n",
        "        rerank_top_n: Number of fused results to rerank (reduces cross-encoder calls)\n",
        "        final_top_k: Final number of chunks to use for generation\n",
        "        \n",
        "    Returns:\n",
        "        Dictionary with query, answer, retrieved_docs, and pipeline stats\n",
        "    \"\"\"\n",
        "    # Stage 1: Dense retrieval (semantic similarity)\n",
        "    dense_results = dense_vectorstore.similarity_search(query, k=dense_top_n)\n",
        "    \n",
        "    # Stage 2: Sparse retrieval (keyword matching)\n",
        "    bm25_results = bm25_search(query, top_k=bm25_top_n)\n",
        "    \n",
        "    # Stage 3: Fusion (combine rankings with RRF)\n",
        "    fused_results = rrf_fusion(dense_results, bm25_results)[:rerank_top_n]\n",
        "    \n",
        "    # Stage 4: Reranking (refine with cross-encoder)\n",
        "    reranked_results = rerank(query, fused_results, top_k=final_top_k)\n",
        "    \n",
        "    # Stage 5: Build context from top results\n",
        "    context = \"\\n\\n\".join([res[\"doc\"].page_content for res in reranked_results])\n",
        "    \n",
        "    # Stage 6: Generate answer with LLM\n",
        "    prompt = f\"\"\"Use the following context to answer the question. Be concise and accurate.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "    \n",
        "    response = llm.invoke(prompt)\n",
        "    answer = response.content if hasattr(response, 'content') else str(response)\n",
        "    \n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"answer\": answer,\n",
        "        \"retrieved_docs\": reranked_results,\n",
        "        \"num_dense\": len(dense_results),\n",
        "        \"num_bm25\": len(bm25_results),\n",
        "        \"num_fused\": len(fused_results),\n",
        "        \"num_final\": len(reranked_results)\n",
        "    }\n",
        "\n",
        "\n",
        "# Test the complete pipeline\n",
        "print(\"üöÄ Testing Complete Hybrid RAG Pipeline\\n\")\n",
        "test_query = \"What are treatments for eczema?\"\n",
        "result = hybrid_rag_pipeline(test_query)\n",
        "\n",
        "print(f\"Query: {test_query}\")\n",
        "print(f\"\\nPipeline stats:\")\n",
        "print(f\"  Dense retrieval: {result['num_dense']} docs\")\n",
        "print(f\"  BM25 retrieval: {result['num_bm25']} docs\")\n",
        "print(f\"  After fusion: {result['num_fused']} docs\")\n",
        "print(f\"  After reranking: {result['num_final']} docs\")\n",
        "print(f\"\\nFinal Answer:\\n{result['answer']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "**What we learned:**\n",
        "\n",
        "### Retrieval Methods\n",
        "- ‚úÖ **Dense Retrieval** - Vector similarity search with embeddings (ChromaDB)\n",
        "- ‚úÖ **Sparse Retrieval** - BM25 keyword matching (exact terms)\n",
        "- ‚úÖ **Hybrid Fusion** - Reciprocal Rank Fusion (RRF) combining both\n",
        "- ‚úÖ **Reranking** - Cross-encoder for refined relevance scoring\n",
        "\n",
        "### Complete Pipeline\n",
        "```\n",
        "Query ‚Üí Dense (top-N) + BM25 (top-N) ‚Üí Fusion (RRF) ‚Üí Rerank (cross-encoder) ‚Üí Final top-k ‚Üí LLM\n",
        "```\n",
        "\n",
        "### When to Use Each Method\n",
        "| Method | Best For | Trade-off |\n",
        "|--------|----------|-----------|\n",
        "| **BM25** | Keyword/exact match queries | Fast, misses synonyms |\n",
        "| **Dense** | Semantic/paraphrase queries | Good accuracy, slower |\n",
        "| **Hybrid** | General queries | Best coverage, more computation |\n",
        "| **Reranking** | High precision needed | Highest accuracy, slowest |\n",
        "\n",
        "### Key Takeaways\n",
        "- No single retrieval method works best for all queries\n",
        "- Hybrid approaches combine strengths of different methods\n",
        "- Two-stage retrieval (fast ‚Üí accurate) balances speed and quality\n",
        "- Cross-encoders are powerful but should be used on small candidate sets\n",
        "\n",
        "**Artifacts:**\n",
        "- `./artifacts/chroma/advanced_dense/`\n",
        "- `./artifacts/manifests/advanced_retrieval.json`"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
