{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3a7e78d5",
      "metadata": {
        "id": "3a7e78d5"
      },
      "source": [
        "## Setup: Imports and Environment Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "51823097",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51823097",
        "outputId": "81424791-6c83-4178-cba9-c35b3259d56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Imports and environment setup complete\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
        "sys.path.insert(0, str(project_root))\n",
        "\n",
        "# Load environment variables from .env file\n",
        "#load_dotenv(project_root / '.env')\n",
        "\n",
        "# Set OpenAI API key from environment\n",
        "#os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', os.environ.get('OPENAI_API_KEY', ''))\n",
        "#if not os.environ.get('OPENAI_API_KEY'):\n",
        "    #raise ValueError(\"OPENAI_API_KEY not found in .env file or environment variables\")\n",
        "\n",
        "# Import project modules\n",
        "from src.utils.config_loader import load_config\n",
        "from src.ingestion.pdf_loader import load_pdf, clean_text\n",
        "from src.ingestion.chunker import chunk_text\n",
        "from src.ingestion.qa_generator import generate_qa_pairs\n",
        "from src.ingestion.dataset_writer import save_to_jsonl, split_dataset, filter_valid_pairs\n",
        "\n",
        "print(\"✓ Imports and environment setup complete\")\n",
        "#print(f\"✓ Project root: {project_root}\")\n",
        "#print(f\"✓ OpenAI API key loaded: {'Yes' if os.environ.get('OPENAI_API_KEY') else 'No'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0kn-2gAJMKJB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kn-2gAJMKJB",
        "outputId": "405081ce-2871-4db4-f9e2-648a1903eed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ OpenAI API key loaded and set as environment variable\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Retrieve API key from Colab secrets\n",
        "openai_api_key = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Set environment variable for OpenAI client\n",
        "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
        "\n",
        "print(\"✓ OpenAI API key loaded and set as environment variable\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbc45725",
      "metadata": {
        "id": "bbc45725"
      },
      "source": [
        "## Step 1: Load Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5e781d39",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e781d39",
        "outputId": "6fea275f-2013-4f45-d484-95a56df154f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Configuration loaded\n",
            "  Raw data directory: /content/operation-ledger-mind/data/raw (exists: True)\n",
            "  PDF path: /content/operation-ledger-mind/data/raw/2024-Annual-Report.pdf (exists: True)\n",
            "  Output path: /content/operation-ledger-mind/data/output\n",
            "  Chunk size: 1500 characters\n",
            "  Questions per chunk: 10\n",
            "  Categories: hard_facts, strategic_summary, stylistic_creative\n"
          ]
        }
      ],
      "source": [
        "# Load configuration\n",
        "config_path = project_root / 'config' / 'config.yaml'\n",
        "config = load_config(config_path)\n",
        "\n",
        "# Extract data factory configuration\n",
        "df_config = config['data_factory']\n",
        "ingestion_config = df_config['ingestion']\n",
        "chunking_config = df_config['chunking']\n",
        "generation_config = df_config['generation']\n",
        "dataset_config = df_config['dataset']\n",
        "\n",
        "# Get paths\n",
        "raw_data_path = project_root / config['environment']['paths']['raw_data']\n",
        "output_path = project_root / config['environment']['paths']['data_dir'] / 'output'\n",
        "output_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Verify raw_data_path exists\n",
        "if not raw_data_path.exists():\n",
        "    raise FileNotFoundError(f\"Raw data directory not found: {raw_data_path}\")\n",
        "\n",
        "# Get PDF filename from config, with fallback to actual file\n",
        "pdf_filename = config['project']['document']\n",
        "pdf_path = raw_data_path / pdf_filename\n",
        "\n",
        "# If configured PDF doesn't exist, try to find any PDF in the directory\n",
        "if not pdf_path.exists():\n",
        "    pdf_files = list(raw_data_path.glob('*.pdf'))\n",
        "    if pdf_files:\n",
        "        pdf_path = pdf_files[0]\n",
        "        pdf_filename = pdf_path.name\n",
        "        print(f\"⚠ Config PDF '{config['project']['document']}' not found, using: {pdf_filename}\")\n",
        "    else:\n",
        "        raise FileNotFoundError(f\"PDF file not found in {raw_data_path}. Expected: {pdf_path}\")\n",
        "\n",
        "# Verify PDF exists\n",
        "if not pdf_path.exists():\n",
        "    raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
        "\n",
        "print(\"✓ Configuration loaded\")\n",
        "print(f\"  Raw data directory: {raw_data_path} (exists: {raw_data_path.exists()})\")\n",
        "print(f\"  PDF path: {pdf_path} (exists: {pdf_path.exists()})\")\n",
        "print(f\"  Output path: {output_path}\")\n",
        "print(f\"  Chunk size: {chunking_config['chunk_size']} characters\")\n",
        "print(f\"  Questions per chunk: {generation_config['questions_per_chunk']}\")\n",
        "print(f\"  Categories: {', '.join(generation_config['categories'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18158515",
      "metadata": {
        "id": "18158515"
      },
      "source": [
        "## Step 2: PDF Ingestion & Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9be6bf70",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9be6bf70",
        "outputId": "ec64ce84-4b92-4e4e-bbe3-9c3faf88db9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading PDF from: /content/operation-ledger-mind/data/raw/2024-Annual-Report.pdf\n",
            "✓ PDF loaded: 620,266 characters\n",
            "\n",
            "Cleaning text...\n",
            "✓ Text cleaned: 619,806 characters\n",
            "  Reduction: 460 characters (0.1%\n"
          ]
        }
      ],
      "source": [
        "# Load PDF\n",
        "print(f\"Loading PDF from: {pdf_path}\")\n",
        "\n",
        "try:\n",
        "    raw_text = load_pdf(pdf_path)\n",
        "    print(f\"✓ PDF loaded: {len(raw_text):,} characters\")\n",
        "except ValueError as e:\n",
        "    print(f\"Error loading PDF: {e}. Attempting to install pdfplumber...\")\n",
        "    %pip install pdfplumber  # Install pdfplumber if it's missing\n",
        "    raw_text = load_pdf(pdf_path) # Retry loading after installation\n",
        "    print(f\"✓ PDF loaded after installing pdfplumber: {len(raw_text):,} characters\")\n",
        "\n",
        "# Clean text\n",
        "print(\"\\nCleaning text...\")\n",
        "cleaned_text = clean_text(\n",
        "    raw_text,\n",
        "    remove_headers=ingestion_config['remove_headers'],\n",
        "    remove_footers=ingestion_config['remove_footers'],\n",
        "    normalize_whitespace=ingestion_config['normalize_whitespace']\n",
        ")\n",
        "print(f\"✓ Text cleaned: {len(cleaned_text):,} characters\")\n",
        "print(f\"  Reduction: {len(raw_text) - len(cleaned_text):,} characters ({100*(len(raw_text)-len(cleaned_text))/len(raw_text):.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41b59eed",
      "metadata": {
        "id": "41b59eed"
      },
      "source": [
        "## Step 3: Chunking Strategy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e4cbdc3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4cbdc3d",
        "outputId": "d9b4e0f2-57dd-4756-bc48-9f87c92b0c27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunking document...\n",
            "✓ Document chunked into 505 chunks\n",
            "  Average chunk size: 1722 characters\n",
            "  Total characters: 869,643\n",
            "\n",
            "First chunk preview (chunk_id=0):\n",
            "  On Our Way\n",
            "Uber’s Mission\n",
            "We reimagine the way the world moves for the better\n",
            "We are Uber.\n",
            "The go-getters.\n",
            "The kind of people who are relentless about our\n",
            "mission to help people go anywhere and get an...\n"
          ]
        }
      ],
      "source": [
        "# Chunk the document\n",
        "print(\"Chunking document...\")\n",
        "chunks = chunk_text(\n",
        "    cleaned_text,\n",
        "    chunk_size=chunking_config['chunk_size'],\n",
        "    overlap=chunking_config['overlap']\n",
        ")\n",
        "\n",
        "print(f\"✓ Document chunked into {len(chunks)} chunks\")\n",
        "print(f\"  Average chunk size: {sum(len(c['text']) for c in chunks) / len(chunks):.0f} characters\")\n",
        "print(f\"  Total characters: {sum(len(c['text']) for c in chunks):,}\")\n",
        "\n",
        "# Display first chunk preview\n",
        "if chunks:\n",
        "    print(f\"\\nFirst chunk preview (chunk_id={chunks[0]['chunk_id']}):\")\n",
        "    print(f\"  {chunks[0]['text'][:200]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "109b85a9",
      "metadata": {
        "id": "109b85a9"
      },
      "source": [
        "## Step 4: Q/A Generation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "620b34a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "620b34a8",
        "outputId": "2047be56-0a50-41dd-8cd7-1b41877e118a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Configuration:\n",
            "  Question LLM: gpt-4o-mini (temp=0.3)\n",
            "  Answer LLM: gpt-4.1-nano (temp=0.2)\n",
            "  Categories: hard_facts, strategic_summary, stylistic_creative\n"
          ]
        }
      ],
      "source": [
        "# Prepare LLM configurations\n",
        "question_llm_config = {\n",
        "    'provider': generation_config['question_llm']['provider'],\n",
        "    'model': generation_config['question_llm']['model'],\n",
        "    'temperature': generation_config['question_llm']['temperature'],\n",
        "    'max_tokens': generation_config['question_llm']['max_tokens'],\n",
        "    'timeout_seconds': config['providers']['openai']['timeout_seconds'],\n",
        "    'max_retries': config['providers']['openai']['max_retries']\n",
        "}\n",
        "\n",
        "answer_llm_config = {\n",
        "    'provider': generation_config['answer_llm']['provider'],\n",
        "    'model': generation_config['answer_llm']['model'],\n",
        "    'temperature': generation_config['answer_llm']['temperature'],\n",
        "    'max_tokens': generation_config['answer_llm']['max_tokens'],\n",
        "    'timeout_seconds': config['providers']['openai']['timeout_seconds'],\n",
        "    'max_retries': config['providers']['openai']['max_retries']\n",
        "}\n",
        "\n",
        "categories = generation_config['categories']\n",
        "\n",
        "print(\"LLM Configuration:\")\n",
        "print(f\"  Question LLM: {question_llm_config['model']} (temp={question_llm_config['temperature']})\")\n",
        "print(f\"  Answer LLM: {answer_llm_config['model']} (temp={answer_llm_config['temperature']})\")\n",
        "print(f\"  Categories: {', '.join(categories)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "faf19e5c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faf19e5c",
        "outputId": "e051e214-b7c5-4c6f-9111-cbaedda1596f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating Q/A pairs for 505 chunks...\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:   1%|          | 5/505 [00:25<44:38,  5.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 5/505 chunks - 50 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:   2%|▏         | 10/505 [00:55<49:36,  6.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 10/505 chunks - 100 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:   3%|▎         | 15/505 [01:22<45:40,  5.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 15/505 chunks - 150 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:   4%|▍         | 20/505 [01:49<44:44,  5.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 20/505 chunks - 200 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:   5%|▍         | 25/505 [02:16<44:31,  5.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 25/505 chunks - 250 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:   6%|▌         | 30/505 [02:46<49:51,  6.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 30/505 chunks - 300 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:   7%|▋         | 35/505 [03:12<41:01,  5.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 35/505 chunks - 350 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:   8%|▊         | 40/505 [03:39<42:42,  5.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 40/505 chunks - 400 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:   9%|▉         | 45/505 [04:07<40:25,  5.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 45/505 chunks - 450 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  10%|▉         | 50/505 [04:39<47:36,  6.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 50/505 chunks - 500 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  11%|█         | 55/505 [05:10<43:56,  5.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 55/505 chunks - 550 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  12%|█▏        | 60/505 [05:40<45:15,  6.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 60/505 chunks - 600 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  13%|█▎        | 65/505 [06:08<40:26,  5.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 65/505 chunks - 650 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  14%|█▍        | 70/505 [06:34<38:31,  5.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 70/505 chunks - 700 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  15%|█▍        | 75/505 [07:01<38:51,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 75/505 chunks - 750 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  16%|█▌        | 80/505 [07:32<40:00,  5.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 80/505 chunks - 800 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  17%|█▋        | 85/505 [08:00<40:04,  5.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 85/505 chunks - 850 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  18%|█▊        | 90/505 [08:29<40:34,  5.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 90/505 chunks - 900 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  19%|█▉        | 95/505 [08:56<37:58,  5.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 95/505 chunks - 950 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  20%|█▉        | 100/505 [09:24<37:51,  5.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 100/505 chunks - 1000 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  21%|██        | 105/505 [09:51<34:21,  5.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 105/505 chunks - 1050 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  22%|██▏       | 110/505 [10:17<34:38,  5.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 110/505 chunks - 1100 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  23%|██▎       | 115/505 [10:43<32:46,  5.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 115/505 chunks - 1150 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  24%|██▍       | 120/505 [11:12<36:41,  5.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 120/505 chunks - 1200 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  25%|██▍       | 125/505 [11:37<33:15,  5.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 125/505 chunks - 1250 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  26%|██▌       | 130/505 [12:02<31:46,  5.08s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 130/505 chunks - 1300 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  27%|██▋       | 135/505 [12:29<34:22,  5.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 135/505 chunks - 1350 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  28%|██▊       | 140/505 [12:56<32:58,  5.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 140/505 chunks - 1400 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  29%|██▊       | 145/505 [13:24<32:48,  5.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 145/505 chunks - 1450 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  30%|██▉       | 150/505 [13:47<27:48,  4.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 150/505 chunks - 1500 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  31%|███       | 155/505 [14:16<31:13,  5.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 155/505 chunks - 1550 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  32%|███▏      | 160/505 [14:46<33:36,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 160/505 chunks - 1600 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  33%|███▎      | 165/505 [15:12<30:56,  5.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 165/505 chunks - 1650 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  34%|███▎      | 170/505 [15:38<30:42,  5.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 170/505 chunks - 1700 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  35%|███▍      | 175/505 [16:08<30:17,  5.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 175/505 chunks - 1750 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  36%|███▌      | 180/505 [16:33<27:11,  5.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 180/505 chunks - 1800 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  37%|███▋      | 185/505 [17:02<31:07,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 185/505 chunks - 1850 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  38%|███▊      | 190/505 [17:32<32:25,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 190/505 chunks - 1900 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  39%|███▊      | 195/505 [18:02<30:45,  5.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 195/505 chunks - 1950 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  40%|███▉      | 200/505 [18:30<28:53,  5.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 200/505 chunks - 2000 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  41%|████      | 205/505 [18:58<29:11,  5.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 205/505 chunks - 2050 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  42%|████▏     | 210/505 [19:29<31:50,  6.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 210/505 chunks - 2100 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  43%|████▎     | 215/505 [19:58<28:55,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 215/505 chunks - 2150 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  44%|████▎     | 220/505 [20:39<40:35,  8.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 220/505 chunks - 2200 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  45%|████▍     | 225/505 [21:06<27:29,  5.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 225/505 chunks - 2250 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  46%|████▌     | 230/505 [21:36<30:27,  6.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 230/505 chunks - 2300 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  47%|████▋     | 235/505 [22:04<25:44,  5.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 235/505 chunks - 2350 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  48%|████▊     | 240/505 [22:32<25:58,  5.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 240/505 chunks - 2400 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  49%|████▊     | 245/505 [22:56<21:53,  5.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 245/505 chunks - 2450 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  50%|████▉     | 250/505 [23:28<26:41,  6.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 250/505 chunks - 2500 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  50%|█████     | 255/505 [24:00<27:21,  6.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 255/505 chunks - 2550 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  51%|█████▏    | 260/505 [24:30<24:59,  6.12s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 260/505 chunks - 2600 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  52%|█████▏    | 265/505 [25:00<23:55,  5.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 265/505 chunks - 2650 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  53%|█████▎    | 270/505 [25:31<23:14,  5.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 270/505 chunks - 2700 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  54%|█████▍    | 275/505 [26:06<26:21,  6.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 275/505 chunks - 2750 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing chunks:  55%|█████▍    | 276/505 [26:12<24:25,  6.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "⚠ Error processing chunk 275: Failed to generate answers for chunk 275: Failed to parse answers from response: [\n",
            "  \"The net income attributable to Uber Technologies, Inc. for the year ended December 31, 2023, was $1,887 million.\",\n",
            "  \"Adjusted EBITDA excludes certain restructuring and related charges, part of w\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  55%|█████▌    | 280/505 [26:37<24:49,  6.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 280/505 chunks - 2790 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  56%|█████▋    | 285/505 [27:06<22:34,  6.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 285/505 chunks - 2840 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  57%|█████▋    | 290/505 [27:34<20:59,  5.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 290/505 chunks - 2890 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  58%|█████▊    | 295/505 [28:00<18:13,  5.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 295/505 chunks - 2940 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  59%|█████▉    | 300/505 [28:26<18:34,  5.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 300/505 chunks - 2990 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  60%|██████    | 305/505 [28:52<17:18,  5.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 305/505 chunks - 3040 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  61%|██████▏   | 310/505 [29:22<18:05,  5.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 310/505 chunks - 3090 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  62%|██████▏   | 315/505 [29:53<18:47,  5.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 315/505 chunks - 3140 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  63%|██████▎   | 320/505 [30:20<16:50,  5.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 320/505 chunks - 3190 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  64%|██████▍   | 325/505 [30:47<16:54,  5.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 325/505 chunks - 3240 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  65%|██████▌   | 330/505 [31:11<14:22,  4.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 330/505 chunks - 3290 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  66%|██████▋   | 335/505 [31:37<13:57,  4.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 335/505 chunks - 3340 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  67%|██████▋   | 340/505 [32:03<14:38,  5.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 340/505 chunks - 3390 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  68%|██████▊   | 345/505 [32:29<13:47,  5.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 345/505 chunks - 3440 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  69%|██████▉   | 350/505 [32:54<12:31,  4.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 350/505 chunks - 3490 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  70%|███████   | 355/505 [33:18<12:31,  5.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 355/505 chunks - 3540 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  71%|███████▏  | 360/505 [33:44<12:18,  5.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 360/505 chunks - 3590 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  72%|███████▏  | 365/505 [34:10<12:15,  5.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 365/505 chunks - 3640 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  73%|███████▎  | 370/505 [34:33<10:30,  4.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 370/505 chunks - 3690 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  74%|███████▍  | 375/505 [35:02<12:10,  5.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 375/505 chunks - 3740 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  75%|███████▌  | 380/505 [35:28<11:04,  5.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 380/505 chunks - 3790 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  76%|███████▌  | 385/505 [35:57<11:42,  5.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 385/505 chunks - 3840 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  77%|███████▋  | 390/505 [36:24<10:59,  5.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 390/505 chunks - 3890 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  78%|███████▊  | 395/505 [36:57<12:25,  6.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 395/505 chunks - 3940 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  79%|███████▉  | 400/505 [37:25<09:43,  5.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 400/505 chunks - 3990 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  80%|████████  | 405/505 [37:51<08:45,  5.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 405/505 chunks - 4040 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  81%|████████  | 410/505 [38:18<08:29,  5.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 410/505 chunks - 4090 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  82%|████████▏ | 415/505 [38:41<07:00,  4.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 415/505 chunks - 4140 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  83%|████████▎ | 420/505 [39:08<07:21,  5.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 420/505 chunks - 4190 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  84%|████████▍ | 425/505 [39:37<07:53,  5.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 425/505 chunks - 4240 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  85%|████████▌ | 430/505 [40:04<06:54,  5.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 430/505 chunks - 4290 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  86%|████████▌ | 435/505 [40:36<07:13,  6.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 435/505 chunks - 4340 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  87%|████████▋ | 440/505 [41:07<06:50,  6.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 440/505 chunks - 4390 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  88%|████████▊ | 445/505 [41:38<05:59,  6.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 445/505 chunks - 4440 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  89%|████████▉ | 450/505 [42:09<05:38,  6.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 450/505 chunks - 4490 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  90%|█████████ | 455/505 [42:41<05:16,  6.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 455/505 chunks - 4540 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  91%|█████████ | 460/505 [43:06<03:59,  5.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 460/505 chunks - 4590 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  92%|█████████▏| 465/505 [43:37<04:02,  6.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 465/505 chunks - 4640 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  93%|█████████▎| 470/505 [44:02<03:00,  5.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 470/505 chunks - 4690 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  94%|█████████▍| 475/505 [44:25<02:24,  4.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 475/505 chunks - 4740 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  95%|█████████▌| 480/505 [44:54<02:17,  5.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 480/505 chunks - 4790 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  96%|█████████▌| 485/505 [45:26<01:58,  5.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 485/505 chunks - 4840 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  97%|█████████▋| 490/505 [45:58<01:38,  6.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 490/505 chunks - 4890 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  98%|█████████▊| 495/505 [46:22<00:49,  4.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 495/505 chunks - 4940 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks:  99%|█████████▉| 500/505 [46:50<00:25,  5.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 500/505 chunks - 4990 Q/A pairs generated\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing chunks: 100%|██████████| 505/505 [47:16<00:00,  5.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Processed 505/505 chunks - 5040 Q/A pairs generated\n",
            "============================================================\n",
            "\n",
            "✓ Q/A generation complete!\n",
            "  Total Q/A pairs: 5040\n",
            "  Expected: 5050\n",
            "  Failed chunks: 1\n",
            "  Failed chunk IDs: [275]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate Q/A pairs for each chunk\n",
        "all_qa_pairs = []\n",
        "failed_chunks = []\n",
        "\n",
        "print(f\"\\nGenerating Q/A pairs for {len(chunks)} chunks...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for chunk in tqdm(chunks, desc=\"Processing chunks\"):\n",
        "    chunk_id = chunk['chunk_id']\n",
        "\n",
        "    try:\n",
        "        # Generate Q/A pairs for this chunk\n",
        "        qa_pairs = generate_qa_pairs(\n",
        "            chunk=chunk,\n",
        "            question_llm_config=question_llm_config,\n",
        "            answer_llm_config=answer_llm_config,\n",
        "            categories=categories\n",
        "        )\n",
        "\n",
        "        # Add chunk text reference to each pair (optional, for debugging)\n",
        "        for pair in qa_pairs:\n",
        "            pair['chunk_text'] = chunk['text'][:500]  # Store first 500 chars for reference\n",
        "\n",
        "        all_qa_pairs.extend(qa_pairs)\n",
        "\n",
        "        # Progress update\n",
        "        if (chunk_id + 1) % 5 == 0:\n",
        "            print(f\"  Processed {chunk_id + 1}/{len(chunks)} chunks - {len(all_qa_pairs)} Q/A pairs generated\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n⚠ Error processing chunk {chunk_id}: {str(e)}\")\n",
        "        failed_chunks.append(chunk_id)\n",
        "        continue\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\n✓ Q/A generation complete!\")\n",
        "print(f\"  Total Q/A pairs: {len(all_qa_pairs)}\")\n",
        "print(f\"  Expected: {len(chunks) * generation_config['questions_per_chunk']}\")\n",
        "print(f\"  Failed chunks: {len(failed_chunks)}\")\n",
        "if failed_chunks:\n",
        "    print(f\"  Failed chunk IDs: {failed_chunks}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "a202df7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a202df7e",
        "outputId": "f328bafb-ad6b-4575-b04a-77a0d47438d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quality Check:\n",
            "  Valid pairs: 5040\n",
            "  Invalid pairs removed: 0\n",
            "\n",
            "Category Distribution:\n",
            "  strategic_summary: 809 (16.1%)\n",
            "  hard_facts: 3127 (62.0%)\n",
            "  stylistic_creative: 1104 (21.9%)\n",
            "\n",
            "Sample Q/A Pairs:\n",
            "\n",
            "  Example 1 (strategic_summary):\n",
            "    Q: What is Uber's mission as stated in the annual report?...\n",
            "    A: We reimagine the way the world moves for the better...\n",
            "\n",
            "  Example 2 (hard_facts):\n",
            "    Q: For which fiscal year does this annual report apply?...\n",
            "    A: For the fiscal year ended December 31, 2024...\n",
            "\n",
            "  Example 3 (hard_facts):\n",
            "    Q: What is the exact name of the registrant as specified in the charter?...\n",
            "    A: UBER TECHNOLOGIES, INC....\n"
          ]
        }
      ],
      "source": [
        "# Filter out invalid pairs and show statistics\n",
        "valid_pairs = filter_valid_pairs(all_qa_pairs)\n",
        "invalid_count = len(all_qa_pairs) - len(valid_pairs)\n",
        "\n",
        "print(f\"Quality Check:\")\n",
        "print(f\"  Valid pairs: {len(valid_pairs)}\")\n",
        "print(f\"  Invalid pairs removed: {invalid_count}\")\n",
        "\n",
        "# Category distribution\n",
        "category_counts = {}\n",
        "for pair in valid_pairs:\n",
        "    category = pair.get('category', 'unknown')\n",
        "    category_counts[category] = category_counts.get(category, 0) + 1\n",
        "\n",
        "print(f\"\\nCategory Distribution:\")\n",
        "for category, count in category_counts.items():\n",
        "    percentage = 100 * count / len(valid_pairs) if valid_pairs else 0\n",
        "    print(f\"  {category}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "# Display sample Q/A pairs\n",
        "if valid_pairs:\n",
        "    print(f\"\\nSample Q/A Pairs:\")\n",
        "    for i, pair in enumerate(valid_pairs[:3], 1):\n",
        "        print(f\"\\n  Example {i} ({pair.get('category', 'unknown')}):\")\n",
        "        print(f\"    Q: {pair['question'][:100]}...\")\n",
        "        print(f\"    A: {pair['answer'][:100]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d50ccc8",
      "metadata": {
        "id": "6d50ccc8"
      },
      "source": [
        "## Step 5: Dataset Splitting & Storage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "972ed4ee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "972ed4ee",
        "outputId": "b0881b10-7838-4591-ff5d-361178875732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting dataset...\n",
            "✓ Dataset split:\n",
            "  Train set: 4032 pairs (80.0%)\n",
            "  Test set: 1008 pairs (20.0%)\n"
          ]
        }
      ],
      "source": [
        "# Split dataset into train and test sets\n",
        "print(\"Splitting dataset...\")\n",
        "train_pairs, test_pairs = split_dataset(\n",
        "    all_pairs=valid_pairs,\n",
        "    train_split=dataset_config['train_split'],\n",
        "    shuffle=dataset_config['shuffle_before_split'],\n",
        "    seed=dataset_config['seed']\n",
        ")\n",
        "\n",
        "print(f\"✓ Dataset split:\")\n",
        "print(f\"  Train set: {len(train_pairs)} pairs ({100*len(train_pairs)/len(valid_pairs):.1f}%)\")\n",
        "print(f\"  Test set: {len(test_pairs)} pairs ({100*len(test_pairs)/len(valid_pairs):.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "2151acfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2151acfe",
        "outputId": "8ad5d93f-0139-4110-8221-5f43ae7f54ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving datasets...\n",
            "✓ Datasets saved:\n",
            "  Train: /content/operation-ledger-mind/data/output/train.jsonl\n",
            "  Test: /content/operation-ledger-mind/data/output/golden_test_set.jsonl\n",
            "\n",
            "File verification:\n",
            "  Train file size: 3318.8 KB\n",
            "  Test file size: 831.3 KB\n"
          ]
        }
      ],
      "source": [
        "# Save datasets to JSONL files\n",
        "train_file = output_path / dataset_config['train_file']\n",
        "test_file = output_path / dataset_config['test_file']\n",
        "\n",
        "print(f\"\\nSaving datasets...\")\n",
        "save_to_jsonl(train_pairs, train_file)\n",
        "save_to_jsonl(test_pairs, test_file)\n",
        "\n",
        "print(f\"✓ Datasets saved:\")\n",
        "print(f\"  Train: {train_file}\")\n",
        "print(f\"  Test: {test_file}\")\n",
        "\n",
        "# Verify files\n",
        "print(f\"\\nFile verification:\")\n",
        "print(f\"  Train file size: {train_file.stat().st_size / 1024:.1f} KB\")\n",
        "print(f\"  Test file size: {test_file.stat().st_size / 1024:.1f} KB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d39cff7",
      "metadata": {
        "id": "1d39cff7"
      },
      "source": [
        "## Step 6: Verification & Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "fabdaa49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fabdaa49",
        "outputId": "0f1b7953-f990-4d70-8c09-0ac9ebc540e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verifying saved files...\n",
            "\n",
            "Train file samples (first 3):\n",
            "  1. Q: What narrative approach does the company take in discussing its tax assets and p...\n",
            "     Category: stylistic_creative\n",
            "  2. Q: How does the company's approach to stockholder proposals reflect its overall gov...\n",
            "     Category: strategic_summary\n",
            "  3. Q: What factors can cause the effective tax rate to vary for the company?...\n",
            "     Category: hard_facts\n",
            "\n",
            "Test file samples (first 3):\n",
            "  1. Q: How long is each offering period in the Employee Stock Purchase Plan (ESPP)?...\n",
            "     Category: strategic_summary\n",
            "  2. Q: What is the purpose of the Power of Attorney as described in the document?...\n",
            "     Category: hard_facts\n",
            "  3. Q: How does the company plan to improve its cash flows from operating activities in...\n",
            "     Category: strategic_summary\n",
            "\n",
            "============================================================\n",
            "✓ DATA FACTORY PIPELINE COMPLETE!\n",
            "============================================================\n",
            "\n",
            "Summary:\n",
            "  • PDF processed: 2024-Annual-Report.pdf\n",
            "  • Chunks created: 505\n",
            "  • Total Q/A pairs: 5040\n",
            "  • Train set: 4032 pairs\n",
            "  • Test set: 1008 pairs\n",
            "  • Output directory: /content/operation-ledger-mind/data/output\n"
          ]
        }
      ],
      "source": [
        "# Load and verify a few samples from each file\n",
        "print(\"Verifying saved files...\\n\")\n",
        "\n",
        "# Check train file\n",
        "with open(train_file, 'r', encoding='utf-8') as f:\n",
        "    train_samples = [json.loads(line) for line in f.readlines()[:3]]\n",
        "\n",
        "print(f\"Train file samples (first 3):\")\n",
        "for i, sample in enumerate(train_samples, 1):\n",
        "    print(f\"  {i}. Q: {sample['question'][:80]}...\")\n",
        "    print(f\"     Category: {sample.get('category', 'N/A')}\")\n",
        "\n",
        "# Check test file\n",
        "with open(test_file, 'r', encoding='utf-8') as f:\n",
        "    test_samples = [json.loads(line) for line in f.readlines()[:3]]\n",
        "\n",
        "print(f\"\\nTest file samples (first 3):\")\n",
        "for i, sample in enumerate(test_samples, 1):\n",
        "    print(f\"  {i}. Q: {sample['question'][:80]}...\")\n",
        "    print(f\"     Category: {sample.get('category', 'N/A')}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"✓ DATA FACTORY PIPELINE COMPLETE!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  • PDF processed: {pdf_filename}\")\n",
        "print(f\"  • Chunks created: {len(chunks)}\")\n",
        "print(f\"  • Total Q/A pairs: {len(valid_pairs)}\")\n",
        "print(f\"  • Train set: {len(train_pairs)} pairs\")\n",
        "print(f\"  • Test set: {len(test_pairs)} pairs\")\n",
        "print(f\"  • Output directory: {output_path}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}